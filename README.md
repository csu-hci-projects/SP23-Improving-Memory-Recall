# SP23-Improving-Memory-Recall

# Project Description

This project focuses on asessing the differences between a user's preferred settings and a set of settings optimized for memory and recall. During the experiment the above code will be run to administer a testing suite first collecting preferential setting and then asessing a user's performance in terms of accuracy and speed through 3 different tests. Each test is formed from a memory recall evaluation consisting of 1 set of 10-15 words and their definitions. Each test will be administered one at a time and the order of each test will be randomized between subjects. The word font, position, size, and color alongside the time each word and its definition is present on the screen will be based on user input for test 1. For test 2, an amalgamation of user preferences and optimized settings will be used. For test 3, optimized settings based on previous research will be used. These changes in features will be our independent variables designed to evoke change in the dependent variables mentioned later. The order in which tests 1,2,3 are shown will be randomized to ensure a valid correlation outside of increased performance over time. Once the words from a single Test have been shown and looked over by the user, they will be tested on 2 separate features: Correct identification of definition based on a word, and time necessary to recall for each feature. These are our dependent (measured) variables. Additionally, after the Nth set is completed and the user has been tested on it, they will also be subjected to a recall test for the N-1th set. For the final set since there is no N+1th set to retest the Nth set, a dummy set with different settings will be presented but not quizzed. Once completed results will be calculated to determine whether preferential, mixed, or optimized settings outperform each other. Additionally, as the time allotted to each card may make a substantial difference a penalty coefficient will be implemented to reduce the score for tests in which a high allotted time per card is used. Finally a correlative value can be calculated between the user chosen features, the ones they performed best on, and the optimized features. In this way we seek to show that a user's preference may outweight a selection of the best criterion for textual memorization.

# Checkpoint 1

## Meeting Times

We had group meetings at least once a week, aiming for twice a week. Typically, this happened on Mondays and Thursdays. Similar to the sprint approach, we made use of this time to debug problems, showcase new ideas, create new ideas in Jira, etc. We will continue to use Jira and allocate assignments appropriately for future work discussions. 

## Contributions

NOTE: Everyone in this group contributed towards research of this project.

### Zachary Fuller

Most of the summary and opening were written by Zach. He was mostly in charge of testing suite implementation. He dealt. Not only that, but he is the author of the project's original concept. 

### Jake Ritz
Jake was in charge of the Unity's initial survey code. Initially, Unity was going to generate a connection to a Google form. After much testing and running into problems, it was decided that it would be best to maintain Google Forms separate. 

### Hunter Hoden
The Related Works Section was finished by Hunter. He also added buttons for font and font color and incorporated hiding overlays.

### Jay Snellings
Jay created all of the menus from scratch, Added functionality to buttons so the menus actually flow and eventually change scenes, contributed to the procurement of research articles to use in the paper

## Video Link 
https://youtu.be/RlbWard5Kow

## Initial Test Survey
https://docs.google.com/forms/d/e/1FAIpQLSdkFUMu80FYO-s8Bf0UadQsE05TnrlH827XOuMJVdF9Macyyw/viewform?usp=sf_link

# Checkpoint 2

## Meeting Times

At least once a week, if not twice, we held group meetings. This usually occurred on Mondays and Thursdays. We used this time, much like the sprint method, to fix issues, provide fresh ideas, add new concepts to Jira, etc.

## Contributions

NOTE: Everyone in this group contributed towards research of this project.

### Zachary Fuller

### Jake Ritz

Jake worked on the team's research paper. He managed all the citations, ensuring proper referencing and formatting were adhered to. Jake also helped fix the issues regarding the Related Works section, aligning it with the research objectives, and collaborated with Zach to create the Procedure section. He also helped with bug fixes, provided ideas when needed, and worked with the testing UI. He's also in the beginning stages of ideating how the experiment will be conducted. 

### Hunter Hoden
- Added functionality to the following parts of the prototype:
  - Font Type selection.
  - Font Size selection.
  - Font Color selection.
  - Background Color selection.
- Complete VR Overhall:
  - Menus.
  - Scenes.
  - Cameras.
- A vast array of bugfixes due to VR port.
- Assisted in implementing the base code for loading and setting user options.

### Jay Snellings

- Created menus for the prototype.
  - Main menu. 
  - Options menu. 
  - Accompanying edits to functionality.
- Various button implementations. 
- Flashcard scene.
  - Basic functionality.
  - Timed flip implementation.
- Cleaned UX/UI of the prototype.
- Implementation of results screen.

## Video Link 

## Overleaf Link 

https://www.overleaf.com/read/fhfwzfvydjhy
